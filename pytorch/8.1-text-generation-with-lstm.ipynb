{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instructional-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-communist",
   "metadata": {},
   "source": [
    "To start using zoo.orca, we need to first initialize orca context. Here we specify local or distributed mode. In this example, we choose the local mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amber-reaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing orca context\n",
      "Current pyspark location is : /intern/spark/spark-2.4.3-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/__init__.py\n",
      "Start to getOrCreate SparkContext\n",
      "pyspark_submit_args is:  --driver-class-path /home/zhenhao/analytics-zoo/zoo/target/analytics-zoo-bigdl_0.12.1-spark_2.4.3-0.10.0-SNAPSHOT-dist-all/lib/analytics-zoo-bigdl_0.12.1-spark_2.4.3-0.10.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/zhenhao/analytics-zoo/zoo/target/analytics-zoo-bigdl_0.12.1-spark_2.4.3-0.10.0-SNAPSHOT-dist-all/lib/analytics-zoo-bigdl_0.12.1-spark_2.4.3-0.10.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/intern/spark/spark-2.4.3-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-24 08:05:31 WARN  Utils:66 - Your hostname, intern01 resolves to a loopback address: 127.0.1.1; using 10.239.44.107 instead (on interface eno1)\n",
      "2021-02-24 08:05:31 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2021-02-24 08:05:32 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.Sample\n",
      "BigDLBasePickler registering: bigdl.util.common  Sample\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult\n",
      "BigDLBasePickler registering: bigdl.util.common  EvaluatedResult\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.JTensor\n",
      "BigDLBasePickler registering: bigdl.util.common  JTensor\n",
      "cls.getname: com.intel.analytics.bigdl.python.api.JActivity\n",
      "BigDLBasePickler registering: bigdl.util.common  JActivitySuccessfully got a SparkContext\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=1\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='1'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from zoo.orca import init_orca_context, stop_orca_context\n",
    "from zoo.orca import OrcaContext\n",
    "\n",
    "# recommended to set it to True when running Analytics Zoo in Jupyter notebook. \n",
    "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
    "\n",
    "cluster_mode = \"local\"\n",
    "\n",
    "if cluster_mode == \"local\":\n",
    "    init_orca_context(cores=1, memory=\"2g\")   # run in local mode\n",
    "elif cluster_mode == \"k8s\":\n",
    "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
    "elif cluster_mode == \"yarn\":\n",
    "    init_orca_context(\n",
    "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
    "        driver_memory=\"10g\", driver_cores=1,\n",
    "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
    "              \"spark.task.maxFailures\": \"1\",\n",
    "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"})   # run on Hadoop YARN cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-person",
   "metadata": {},
   "source": [
    "# Text generation with LSTM\n",
    "This notebook contains the code samples found in Chapter 8, Section 1 of Deep Learning with Python. Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "-----------------------------------------\n",
    "\n",
    "[...]\n",
    "\n",
    "## Implementing character-level LSTM text generation\n",
    "Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a language model. You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. In this example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). The language model we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the English language.\n",
    "\n",
    "## Preparing the data\n",
    "Let's start by downloading the corpus and converting it to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solved-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-wheel",
   "metadata": {},
   "source": [
    "Next, we will extract partially-overlapping sequences of length maxlen, one-hot encode them and pack them in a 3D Numpy array `x` of shape `(sequences, maxlen, unique_characters)`. Simultaneously, we prepare a array `y` containing the corresponding targets: the one-hot encoded characters that come right after each extracted sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sharing-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "finished-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[0:2000]\n",
    "y = y[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sitting-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "_, y_labels = torch.tensor(y).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "trying-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 40,  1,  ..., 40, 35, 46])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-short",
   "metadata": {},
   "source": [
    "\n",
    "## Building the network\n",
    "Our network is a single LSTM layer followed by a Dense classifier and softmax over all possible characters. But let us note that recurrent neural networks are not the only way to do sequence data generation; 1D convnets also have proven extremely successful at it in recent times. Since our targets are one-hot encoded, we will use `categorical_crossentropy` as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(config):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "    model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "major-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, maxlen, chars):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=len(chars), hidden_size=128, num_layers=1)\n",
    "        self.fc = nn.Linear(128, len(chars))\n",
    "        \n",
    "        self.maxlen = maxlen\n",
    "        self.chars = chars\n",
    "\n",
    "    def forward(self, x):\n",
    "        batches = x.size(0)\n",
    "        h0 = torch.zeros([1, self.maxlen, 128])\n",
    "        c0 = torch.zeros([1, self.maxlen, 128])\n",
    "        (x, _) = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "model = LSTMNet(maxlen, chars)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-scientist",
   "metadata": {},
   "source": [
    "We also create a `data_creator` function that help us import the data into the orca estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "verbal-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def train_data_creator(config, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(config[\"batch_size\"])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "flexible-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def data_loader_creator(data, targets, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Transforms data and targets from np.array to torch.utils.data.DataLoader,\n",
    "    and shuffle the dataset if `shuffle` is set to true.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_tensor = torch.Tensor([np.array(x) for x in data])\n",
    "    targets_tensor = torch.Tensor([np.array([x]) for x in targets])\n",
    "    dataset = TensorDataset(data_tensor, targets_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "compliant-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_loader_creator(x, y_labels, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_loader:\n",
    "    print(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-vacation",
   "metadata": {},
   "source": [
    "Training the language model and sampling from it\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "* 1) Drawing from the model a probability distribution over the next character given the text available so far\n",
    "* 2) Reweighting the distribution to a certain \"temperature\"\n",
    "* 3) Sampling the next character at random according to the reweighted distribution\n",
    "* 4) Adding the new character at the end of the available text\n",
    "\n",
    "This is the code we use to reweight the original probability distribution coming out of the model, and draw a character index from it (the \"sampling function\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-prospect",
   "metadata": {},
   "source": [
    "Finally, this is the loop where we repeatedly train and generated text. We start generating text using a range of different temperatures after every epoch. This allows us to see how the generated text evolves as the model starts converging, as well as the impact of temperature in the sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "periodic-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasAccuracy\n",
      "creating: createTorchLoss\n",
      "creating: createTorchOptim\n",
      "creating: createTorchModel\n",
      "creating: createEstimator\n"
     ]
    }
   ],
   "source": [
    "from zoo.orca.learn.pytorch import Estimator \n",
    "from zoo.orca.learn.metrics import Accuracy\n",
    "\n",
    "est = Estimator.from_torch(model=model, optimizer=opt, loss=criterion, metrics=[Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "parallel-spell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createMaxEpoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 16:22:22 INFO  DistriOptimizer$:818 - caching training rdd ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:649 - Cache thread models...\n",
      "2021-02-23 16:22:35 WARN  DistriOptimizer$:604 - Partitions of the training data are not evenlydistributed across the executors in the Spark cluster; are there sufficient trainingdata to be distributed?\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:632 - model thread pool size is 1\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:651 - Cache thread models... done\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:161 - Count dataset\n",
      "Warn: jep.JepException: <class 'StopIteration'>\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:165 - Count dataset complete. Time elapsed: 0.036821829s\n",
      "Warn: jep.JepException: <class 'StopIteration'>\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2021-02-23 16:22:35 WARN  DistriOptimizer$:167 - If the dataset is built directly from RDD[Minibatch], the data in each minibatch is fixed, and a single minibatch is randomly selected in each partition. If the dataset is transformed from RDD[Sample], each minibatch will be constructed on the fly from random samples, which is better for convergence.\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:173 - config  {\n",
      "\tcomputeThresholdbatchSize: 100\n",
      "\tmaxDropPercentage: 0.0\n",
      "\twarmupIterationNum: 200\n",
      "\tisLayerwiseScaled: false\n",
      "\tdropPercentage: 0.0\n",
      " }\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:177 - Shuffle data\n",
      "2021-02-23 16:22:35 INFO  DistriOptimizer$:180 - Shuffle data complete. Takes 9.215E-5s\n",
      "Warn: jep.JepException: <class 'NameError'>: name 'loaderdc8aba3_0_iter_true' is not defined\n",
      "\tat <string>.<module>(<string>:2)\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Warn: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n",
      "\tat <string>.<module>(<string>:1)\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2021-02-23 16:22:35 ERROR Executor:91 - Exception in task 0.0 in stage 19.0 (TID 19)\n",
      "jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n",
      "\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n",
      "\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n",
      "\tat <string>.<module>(<string>:1)\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\t... 4 more\n",
      "2021-02-23 16:22:35 ERROR TaskSetManager:70 - Task 0 in stage 19.0 failed 1 times; aborting job\n",
      "2021-02-23 16:22:35 ERROR DistriOptimizer$:1287 - Error: java.lang.reflect.InvocationTargetException\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.keras.layers.utils.KerasUtils$.invokeMethod(KerasUtils.scala:302)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.keras.layers.utils.KerasUtils$.invokeMethodWithEv(KerasUtils.scala:329)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$.optimizeModels(Topology.scala:1063)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1262)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1475)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1145)\n",
      "\tat com.intel.analytics.zoo.pipeline.estimator.Estimator.train(Estimator.scala:190)\n",
      "\tat com.intel.analytics.zoo.pipeline.estimator.python.PythonEstimator.estimatorTrainMiniBatch(PythonEstimator.scala:117)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 19, localhost, executor driver): jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n",
      "\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n",
      "\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n",
      "\tat <string>.<module>(<string>:1)\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\t... 4 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n",
      "\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n",
      "\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$.optimize(DistriOptimizer.scala:353)\n",
      "\t... 23 more\n",
      "Caused by: jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n",
      "\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n",
      "\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n",
      "\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n",
      "\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n",
      "\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n",
      "\tat <string>.<module>(<string>:1)\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\t... 4 more\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o51.estimatorTrainMiniBatch.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 19, localhost, executor driver): jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n\tat <string>.<module>(<string>:1)\n\tat jep.Jep.exec(Native Method)\n\tat jep.Jep.exec(Jep.java:478)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\t... 4 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$.optimize(DistriOptimizer.scala:353)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intel.analytics.zoo.pipeline.api.keras.layers.utils.KerasUtils$.invokeMethod(KerasUtils.scala:302)\n\tat com.intel.analytics.zoo.pipeline.api.keras.layers.utils.KerasUtils$.invokeMethodWithEv(KerasUtils.scala:329)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$.optimizeModels(Topology.scala:1063)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1262)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1475)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1145)\n\tat com.intel.analytics.zoo.pipeline.estimator.Estimator.train(Estimator.scala:190)\n\tat com.intel.analytics.zoo.pipeline.estimator.python.PythonEstimator.estimatorTrainMiniBatch(PythonEstimator.scala:117)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n\tat <string>.<module>(<string>:1)\n\tat jep.Jep.exec(Native Method)\n\tat jep.Jep.exec(Jep.java:478)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\t... 4 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8320d5624302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/analytics-zoo/pyzoo/zoo/orca/learn/pytorch/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, epochs, batch_size, feature_cols, label_cols, validation_data, checkpoint_trigger)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mtrain_fset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_fset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hanle_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             self.estimator.train_minibatch(train_fset, self.loss, end_trigger,\n\u001b[0;32m--> 298\u001b[0;31m                                            checkpoint_trigger, val_fset, self.metrics)\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             raise ValueError(\"Data and validation data should be SparkXShards, DataLoaders or \"\n",
      "\u001b[0;32m~/analytics-zoo/pyzoo/zoo/pipeline/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, train_set, criterion, end_trigger, checkpoint_trigger, validation_set, validation_method)\u001b[0m\n\u001b[1;32m    166\u001b[0m         callZooFunc(self.bigdl_type, \"estimatorTrainMiniBatch\", self.value, train_set,\n\u001b[1;32m    167\u001b[0m                     \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_trigger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_trigger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                     validation_method)\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analytics-zoo/pyzoo/zoo/common/utils.py\u001b[0m in \u001b[0;36mcallZooFunc\u001b[0;34m(bigdl_type, name, *args)\u001b[0m\n\u001b[1;32m    131\u001b[0m             if not (\"does not exist\" in str(e)\n\u001b[1;32m    132\u001b[0m                     and \"Method {}\".format(name) in str(e)):\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analytics-zoo/pyzoo/zoo/common/utils.py\u001b[0m in \u001b[0;36mcallZooFunc\u001b[0;34m(bigdl_type, name, *args)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjinvoker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mjava_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/intern/spark/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/intern/spark/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o51.estimatorTrainMiniBatch.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 19, localhost, executor driver): jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n\tat <string>.<module>(<string>:1)\n\tat jep.Jep.exec(Native Method)\n\tat jep.Jep.exec(Jep.java:478)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\t... 4 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$.optimize(DistriOptimizer.scala:353)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.intel.analytics.zoo.pipeline.api.keras.layers.utils.KerasUtils$.invokeMethod(KerasUtils.scala:302)\n\tat com.intel.analytics.zoo.pipeline.api.keras.layers.utils.KerasUtils$.invokeMethodWithEv(KerasUtils.scala:329)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$.optimizeModels(Topology.scala:1063)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1262)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1475)\n\tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalDistriOptimizer.train(Topology.scala:1145)\n\tat com.intel.analytics.zoo.pipeline.estimator.Estimator.train(Estimator.scala:190)\n\tat com.intel.analytics.zoo.pipeline.estimator.python.PythonEstimator.estimatorTrainMiniBatch(PythonEstimator.scala:117)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: jep.JepException: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:100)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:110)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:71)\n\tat com.intel.analytics.zoo.pipeline.api.net.TorchLoss.updateOutput(TorchLoss.scala:27)\n\tat com.intel.analytics.bigdl.nn.abstractnn.AbstractCriterion.forward(AbstractCriterion.scala:73)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply$mcI$sp(DistriOptimizer.scala:270)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.optim.DistriOptimizer$$anonfun$4$$anonfun$5$$anonfun$apply$2.apply(DistriOptimizer.scala:260)\n\tat com.intel.analytics.bigdl.utils.ThreadPool$$anonfun$1$$anon$5.call(ThreadPool.scala:160)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: jep.JepException: <class 'RuntimeError'>: 1D target tensor expected, multi-target not supported\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.nll_loss(functional.py:2264)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/functional.cross_entropy(functional.py:2468)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/loss.forward(loss.py:962)\n\tat /home/zhenhao/.local/lib/python3.7/site-packages/torch/nn/modules/module._call_impl(module.py:727)\n\tat <string>.<module>(<string>:1)\n\tat jep.Jep.exec(Native Method)\n\tat jep.Jep.exec(Jep.java:478)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\t... 4 more\n"
     ]
    }
   ],
   "source": [
    "est.fit(data=train_loader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-relative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-pipeline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zoo.orca.data import XShards\n",
    "\n",
    "batch_size=128\n",
    "output = \"\"\n",
    "for epoch in range(1, 60):\n",
    "    #print('epoch', epoch)\n",
    "    output += \"epoch \" + str(epoch) + '\\n'\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    est.fit(data=train_loader, epochs=epoch)\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    #print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    output += '--- Generating with seed: \"' + str(generated_text) + '\"\\n'\n",
    "    model = est.get_model()\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        #print('------ temperature:', temperature)\n",
    "        output += '------ temperature: ' + str(temperature) + '\\n'\n",
    "        #sys.stdout.write(generated_text)\n",
    "        output += generated_text\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "                \n",
    "            sample_shards = XShards.partition({\"x\": sampled}, num_shards=1)\n",
    "            preds = est.predict(sample_shards).collect()\n",
    "            \n",
    "            #preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            \n",
    "            \n",
    "            #next_index = sample(preds[0]['prediction'][0], temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            #sys.stdout.write(next_char)\n",
    "            output += next_char\n",
    "            #sys.stdout.flush()\n",
    "        #print()\n",
    "        output += '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-validation",
   "metadata": {},
   "source": [
    "As you can see, a low temperature results in extremely repetitive and predictable text, but where local structure is highly realistic: in particular, all words (a word being a local pattern of characters) are real English words. With higher temperatures, the generated text becomes more interesting, surprising, even creative; it may sometimes invent completely new words that sound somewhat plausible (such as \"eterned\" or \"troveration\"). With a high temperature, the local structure starts breaking down and most words look like semi-random strings of characters. Without a doubt, here 0.5 is the most interesting temperature for text generation in this specific setup. Always experiment with multiple sampling strategies! A clever balance between learned structure and randomness is what makes generation interesting.\n",
    "\n",
    "Note that by training a bigger model, longer, on more data, you can achieve generated samples that will look much more coherent and realistic than ours. But of course, don't expect to ever generate any meaningful text, other than by random chance: all we are doing is sampling data from a statistical model of which characters come after which characters. Language is a communication channel, and there is a distinction between what communications are about, and the statistical structure of the messages in which communications are encoded. To evidence this distinction, here is a thought experiment: what if human language did a better job at compressing communications, much like our computers do with most of our digital communications? Then language would be no less meaningful, yet it would lack any intrinsic statistical structure, thus making it impossible to learn a language model like we just did.\n",
    "\n",
    "## Take aways\n",
    "* We can generate discrete sequence data by training a model to predict the next tokens(s) given previous tokens.\n",
    "* In the case of text, such a model is called a \"language model\" and could be based on either words or characters.\n",
    "* Sampling the next token requires balance between adhering to what the model judges likely, and introducing randomness.\n",
    "* One way to handle this is the notion of softmax temperature. Always experiment with different temperatures to find the \"right\" one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "est.shutdown()\n",
    "stop_orca_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
