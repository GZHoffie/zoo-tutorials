{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "august-telescope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-turning",
   "metadata": {},
   "source": [
    "To start using `zoo.orca`, we need to first initialize orca context. Here we specify local or distributed mode. In this example, we choose the local mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoo.orca import init_orca_context, stop_orca_context\n",
    "from zoo.orca import OrcaContext\n",
    "\n",
    "# recommended to set it to True when running Analytics Zoo in Jupyter notebook. \n",
    "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
    "\n",
    "cluster_mode = \"local\"\n",
    "\n",
    "if cluster_mode == \"local\":\n",
    "    init_orca_context(cores=1, memory=\"2g\")   # run in local mode\n",
    "elif cluster_mode == \"k8s\":\n",
    "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
    "elif cluster_mode == \"yarn\":\n",
    "    init_orca_context(\n",
    "        cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
    "        driver_memory=\"10g\", driver_cores=1,\n",
    "        conf={\"spark.rpc.message.maxSize\": \"1024\",\n",
    "              \"spark.task.maxFailures\": \"1\",\n",
    "              \"spark.driver.extraJavaOptions\": \"-Dbigdl.failure.retryTimes=1\"})   # run on Hadoop YARN cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-extra",
   "metadata": {},
   "source": [
    "# 5.1 - Introduction to convnets\n",
    "This notebook contains the code sample found in Chapter 5, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "-------------------------------------------------------------\n",
    "\n",
    "First, let's take a practical look at a very simple convnet example. We will use our convnet to classify MNIST digits, a task that you've already been through in Chapter 2, using a densely-connected network (our test accuracy then was 97.8%). Even though our convnet will be very basic, its accuracy will still blow out of the water that of the densely-connected model from Chapter 2.\n",
    "\n",
    "The 6 lines of code below show you what a basic convnet looks like. It's a stack of Conv2D and MaxPooling2D layers. We'll see in a minute what they do concretely. Importantly, a convnet takes as input tensors of shape `(image_height, image_width, image_channels)` (not including the batch dimension). In our case, we will configure our convnet to process inputs of size `(28, 28, 1)`, which is the format of MNIST images. We do this via passing the argument `input_shape=(28, 28, 1)` to our first layer.\n",
    "\n",
    "You can see above that the output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. The width and height dimensions tend to shrink as we go deeper in the network. The number of channels is controlled by the first argument passed to the `Conv2D` layers (e.g. 32 or 64).\n",
    "\n",
    "The next step would be to feed our last output tensor (of shape `(3, 3, 64)`) into a densely-connected classifier network like those you are already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas our current output is a 3D tensor. So first, we will have to flatten our 3D outputs to 1D, and then add a few Dense layers on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legitimate-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(3*3*64, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 3*3*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "model = ConvNet()\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-riverside",
   "metadata": {},
   "source": [
    "Let's display the architecture of our convnet so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ultimate-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-president",
   "metadata": {},
   "source": [
    "We are going to do 10-way classification, so we use a final layer with 10 outputs and a softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-reserve",
   "metadata": {},
   "source": [
    "As you can see, our `(3, 3, 64)` outputs were flattened into vectors of shape `(576,)`, before going through two Dense layers.\n",
    "\n",
    "Now, let's train our convnet on the MNIST digits. We will reuse a lot of the code we have already covered in the MNIST example from Chapter 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.manual_seed(0)\n",
    "dir='./dataset'\n",
    "batch_size=64\n",
    "test_batch_size=64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(dir, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(dir, train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-legislature",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createZooKerasAccuracy\n",
      "creating: createTorchLoss\n",
      "creating: createTorchOptim\n",
      "creating: createTorchModel\n",
      "creating: createEstimator\n"
     ]
    }
   ],
   "source": [
    "from zoo.orca.learn.pytorch import Estimator \n",
    "from zoo.orca.learn.metrics import Accuracy\n",
    "\n",
    "est = Estimator.from_torch(model=model, optimizer=opt, loss=criterion, metrics=[Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoo.orca.learn.trigger import EveryEpoch \n",
    "\n",
    "est.fit(data=train_loader, epochs=5, checkpoint_trigger=EveryEpoch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-yeast",
   "metadata": {},
   "source": [
    "We can see that our model gives a high accuracy in the training set, about 99.4%. Let's evaluate the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "functioning-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9390:>                                                       (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warn: jep.JepException: <class 'StopIteration'>\n",
      "\tat jep.Jep.exec(Native Method)\n",
      "\tat jep.Jep.exec(Jep.java:478)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:108)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:107)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n",
      "\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2021-02-23 12:25:45 INFO  DistriOptimizer$:1759 - Top1Accuracy is Accuracy(correct: 9906, count: 10000, accuracy: 0.9906)\n",
      "Top1Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = est.evaluate(data=test_loader)\n",
    "for r in result:\n",
    "    print(str(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-active",
   "metadata": {},
   "source": [
    "While our densely-connected network from Chapter 2 had a test accuracy of 97.8%, our basic convnet has a test accuracy of 99.1%: we decreased our error rate by 58% (relative). Not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comfortable-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping orca context\n"
     ]
    }
   ],
   "source": [
    "# stop orca context and shut down the estimator when program finishes\n",
    "stop_orca_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
